{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4e3e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b777065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52ff902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b29738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "    feedback: str = Field(description=\"Detailed feedback for the essay\")\n",
    "    score: int = Field(description=\"Score out of 10\", ge=0, le=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b116a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef93b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\"\"Global warmming is like when its hot outside but like not the normal hot its more hotter than before. So people say its a problem but like also its nature and maybe nature just doing its thing. I saw on TV that like the polar bears are sad, which is not cool but also how do we know they are sad? Maybe they like it warm? Idk.\n",
    "\n",
    "Anyways, carbon dioxside is like something cars do and when theres more cars, theres more carbon and it goes up and then its bad. But also planes do that too. And cows? Cows fart and that makes climate worst which is funny cause cows are cute lol. If we stop cows then no burgers, and that would be also bad so it's complicated.\n",
    "\n",
    "Some people say recycle and turn off lights and stuff, but also some people still use plastic so it's kinda like why even bother? The earth is big and people are small so it canâ€™t really matter that much if I throw away a bottle, right?\n",
    "\n",
    "In conclusion, global warming is like a thing that is happening or maybe not, it depends. Some say it's fake, some say it's real, and the truth is probably somewhere in the middle. The ice is melting but maybe it'll stop melting later. We just have to wait and see what happens I guess.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49387de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationSchema(feedback='The essay demonstrates a basic understanding of global warming but lacks depth and accuracy. The language is informal and contains grammatical errors. The tone is dismissive and uncertain, failing to convey the seriousness of the issue.  Recommendations include:  - using more precise language and scientific terminology; - providing more factual information and evidence; - adopting a more serious and informative tone; - exploring the issue in greater detail, discussing potential solutions and consequences.', score=4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "structured_model.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f1dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPSCState(TypedDict):\n",
    "    essay: str\n",
    "    language_feedback: str\n",
    "    analysis_feedback: str\n",
    "    clarity_feedback: str\n",
    "    overall_feedback: str\n",
    "    individual_scores: Annotated[list[int], operator.add]\n",
    "    avg_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8fc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96fab5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(state: UPSCState):\n",
    "    essay = state['essay']\n",
    "\n",
    "    prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'language_feedback':output.feedback, \"individual_scores\":[output.score]}\n",
    "\n",
    "\n",
    "def evaluate_analysis(state: UPSCState):\n",
    "    essay = state['essay']\n",
    "\n",
    "    prompt = f'Evaluate the depth of analysis of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'analysis_feedback':output.feedback, \"individual_scores\":[output.score]}\n",
    "\n",
    "\n",
    "def evaluate_thought(state: UPSCState):\n",
    "    essay = state['essay']\n",
    "\n",
    "    prompt = f'Evaluate the clarity of thought of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'clarity_feedback':output.feedback, \"individual_scores\":[output.score]}\n",
    "\n",
    "\n",
    "def final_evaluation(state: UPSCState):\n",
    "    prompt = f'Based on the following feedbacks create a summarized feedback \\n language feedback - {state[\"language_feedback\"]} \\n depth of analysis feedback - {state[\"analysis_feedback\"]} \\n clarity of thought feedback - {state[\"clarity_feedback\"]}'\n",
    "    overall_feedback = model.invoke(prompt).content\n",
    "\n",
    "    avg_score = sum(state['individual_scores'])/len(state['individual_scores'])\n",
    "\n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': avg_score}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb456bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x13b1915e4a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "graph.add_node(\"evaluate_language\",evaluate_language)\n",
    "graph.add_node(\"evaluate_analysis\",evaluate_analysis)\n",
    "graph.add_node(\"evaluate_thought\",evaluate_thought)\n",
    "graph.add_node(\"final_evaluation\",final_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec57cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33394ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf3f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a950927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
